/**
 * src/screens/MainScreen.tsx
 * 
 * WCAG 2.1 Level AA Compliant Main Screen
 * 
 * Critical Accessibility Features:
 * - 1.1.1 Non-text Content: All visual elements have text alternatives
 * - 1.3.1 Info and Relationships: Proper semantic structure
 * - 2.1.1 Keyboard: Full screen reader operability
 * - 2.4.3 Focus Order: Logical navigation sequence  
 * - 2.4.7 Focus Visible: Clear focus indicators
 * - 2.5.1 Pointer Gestures: Single-tap AND double-tap work
 * - 2.5.2 Pointer Cancellation: Actions on release
 * - 3.2.1 On Focus: No unexpected changes
 * - 3.3.1 Error Identification: Clear error descriptions
 * - 3.3.2 Labels or Instructions: Complete guidance
 * - 4.1.2 Name, Role, Value: Complete accessibility props
 * - 4.1.3 Status Messages: Live status announcements
 * 
 * ZERO TOLERANCE FOR ACCESSIBILITY ERRORS
 * This app serves blind users who depend entirely on audio feedback
 */

import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  StyleSheet,
  TouchableOpacity,
  Text,
  Alert,
  ActivityIndicator,
  AccessibilityInfo,
  Platform,
  Vibration,
} from 'react-native';
import { Camera } from 'react-native-vision-camera';
import VoiceButton from '../components/VoiceButton';
import VisualFeedback from '../components/VisualFeedback';
import { useVoiceRecognition } from '../hooks/useVoiceRecognition';
import { useCamera } from '../hooks/useCamera';
import { useTTS } from '../hooks/useTTS';
import { sendToWorkflow } from '../services/WorkflowService';
import { requestPermissions } from '../services/PermissionService';
import { COLORS } from '../utils/constants';
import { ReachingBridge, ReachingEvents } from '../native/ReachingModule';

const MainScreen: React.FC = () => {
  // ============================================================================
  // State Management
  // ============================================================================
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [hasPermissions, setHasPermissions] = useState(false);
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [screenReaderEnabled, setScreenReaderEnabled] = useState(false);
  const [reduceMotionEnabled, setReduceMotionEnabled] = useState(false);
  
  // ============================================================================
  // Hooks
  // ============================================================================
  const { startRecognition, stopRecognition, cancelRecognition } = useVoiceRecognition();
  const { device, cameraRef, capturePhoto } = useCamera();
  const { speak, stop: stopTTS } = useTTS();

  // ============================================================================
  // Refs for state tracking
  // ============================================================================
  const previousStateRef = useRef<string>('');
  const isProcessingRef = useRef(false);

  // ============================================================================
  // WCAG 2.3.3 & 1.4.13: Check Accessibility Preferences
  // ============================================================================
  useEffect(() => {
    const checkAccessibilityPreferences = async () => {
      try {
        const [isScreenReaderOn, isReduceMotionOn] = await Promise.all([
          AccessibilityInfo.isScreenReaderEnabled(),
          AccessibilityInfo.isReduceMotionEnabled(),
        ]);
        
        setScreenReaderEnabled(isScreenReaderOn);
        setReduceMotionEnabled(isReduceMotionOn);
        
        console.log('‚ôø Accessibility:', {
          screenReader: isScreenReaderOn,
          reduceMotion: isReduceMotionOn,
        });

        // WCAG 4.1.3: Welcome announcement for screen reader users
        if (isScreenReaderOn && hasPermissions) {
          setTimeout(() => {
            AccessibilityInfo.announceForAccessibility(
              'ShelfScout activated. Use the voice button to start recording. Double tap the button to take a photo immediately.'
            );
          }, 1000);
        }
      } catch (error) {
        console.error('‚ùå Accessibility check error:', error);
      }
    };

    checkAccessibilityPreferences();

    // Listen for accessibility setting changes
    const screenReaderSubscription = AccessibilityInfo.addEventListener(
      'screenReaderChanged',
      setScreenReaderEnabled
    );
    
    const reduceMotionSubscription = AccessibilityInfo.addEventListener(
      'reduceMotionChanged',
      setReduceMotionEnabled
    );

    return () => {
      screenReaderSubscription?.remove();
      reduceMotionSubscription?.remove();
    };
  }, [hasPermissions]);

  // ============================================================================
  // WCAG 3.3.2: Initialize permissions on mount
  // ============================================================================
  useEffect(() => {
    initializePermissions();
  }, []);

  // ============================================================================
  // WCAG 4.1.3: Announce state changes
  // ============================================================================
  useEffect(() => {
    const currentState = getStateDescription();
    
    // Only announce significant state changes
    if (currentState !== previousStateRef.current && previousStateRef.current !== '') {
      // VoiceButton and VisualFeedback handle most announcements
      // Only announce here if it's a major transition
    }
    
    previousStateRef.current = currentState;
  }, [isRecording, isProcessing, isSpeaking]);

  // ============================================================================
  // Helper: Get current state description
  // ============================================================================
  const getStateDescription = (): string => {
    if (isSpeaking) return 'speaking';
    if (isProcessing) return 'processing';
    if (isRecording) return 'recording';
    return 'ready';
  };

  // ============================================================================
  // WCAG 3.3.1 & 3.3.2: Initialize permissions with error handling
  // ============================================================================
  const initializePermissions = async () => {
    try {
      const granted = await requestPermissions();
      setHasPermissions(granted);
      
      if (!granted) {
        // WCAG 3.3.1: Clear error identification
        const errorMessage = 'ShelfScout needs microphone and camera access to function properly. Please grant these permissions in your device settings.';
        
        // Announce to screen reader
        AccessibilityInfo.announceForAccessibility(
          `Error: ${errorMessage}`
        );
        
        Alert.alert(
          'Permissions Required',
          errorMessage,
          [
            { 
              text: 'OK', 
              style: 'default',
              onPress: () => {
                // Focus on permission button for accessibility
                AccessibilityInfo.announceForAccessibility(
                  'Use the Grant Permissions button to enable access.'
                );
              }
            }
          ]
        );
      } else {
        // Announce success
        AccessibilityInfo.announceForAccessibility(
          'Permissions granted. ShelfScout is ready to use.'
        );
      }
    } catch (error) {
      console.error('‚ùå Permission initialization error:', error);
      
      // WCAG 3.3.1: Announce error
      AccessibilityInfo.announceForAccessibility(
        'Error checking permissions. Please try again or check your device settings.'
      );
    }
  };

  // ============================================================================
  // WCAG 2.5.2: Handle press (action on release, can cancel)
  // ============================================================================
  const handlePress = async () => {
    // WCAG 3.3.2: Check permissions first
    if (!hasPermissions) {
      const message = 'Please grant microphone and camera permissions to use ShelfScout.';
      
      AccessibilityInfo.announceForAccessibility(`Error: ${message}`);
      
      Alert.alert(
        'Permissions Required',
        message,
        [{ text: 'OK', style: 'default' }]
      );
      return;
    }

    // WCAG 3.2.1: Predictable behavior - can stop during speaking
    if (isSpeaking) {
      console.log('üõë Tap during speaking - stopping TTS');
      
      // Announce action
      AccessibilityInfo.announceForAccessibility('Stopping speech.');
      
      await stopTTS();
      setIsSpeaking(false);
      
      // Announce ready state
      AccessibilityInfo.announceForAccessibility(
        'Speech stopped. ShelfScout is ready. Tap to speak.'
      );
      return;
    }

    // WCAG 3.2.1: Ignore tap during processing (requires double-tap)
    if (isProcessing) {
      console.log('‚ö†Ô∏è Ignoring tap - currently processing');
      
      // Inform user
      AccessibilityInfo.announceForAccessibility(
        'ShelfScout is processing. Please wait, or double tap to cancel.'
      );
      return;
    }

    if (isRecording) {
      // Stop recording and process
      console.log('üõë Stop & process');
      
      Vibration.vibrate(50);
      
      // Announce action
      AccessibilityInfo.announceForAccessibility(
        'Stopping recording and processing your command.'
      );
      
      setIsRecording(false);
      await stopRecognition();
      
      if (currentTranscript) {
        await processVoiceCommand(currentTranscript);
      } else {
        // WCAG 3.3.1: No transcript error
        AccessibilityInfo.announceForAccessibility(
          'No voice input detected. Please try again.'
        );
      }
    } else {
      // Start recording
      console.log('üé§ Start listening');
      
      Vibration.vibrate(50);
      
      setIsRecording(true);
      setCurrentTranscript('');
      
      startRecognition(
        handleSpeechResult,
        handleSpeechError,
        () => {
          console.log('üé§ Speech started');
          // Announce via audio feedback service
        },
        () => {
          console.log('üé§ Speech ended');
        }
      );
    }
  };

  // ============================================================================
  // WCAG 2.5.1: Handle double-tap gesture
  // ============================================================================
  const handleDoubleTap = async () => {
    console.log('üëÜüëÜ DOUBLE TAP');
    
    Vibration.vibrate([50, 100, 50]); // Double vibration for double tap
    
    // WCAG 3.2.1: Emergency stop during speaking
    if (isSpeaking) {
      console.log('üö® EMERGENCY STOP - Stopping TTS');
      
      // Announce action
      AccessibilityInfo.announceForAccessibility('Emergency stop. Stopping speech.');
      
      await stopTTS();
      setIsSpeaking(false);
      
      // Announce ready
      AccessibilityInfo.announceForAccessibility(
        'Stopped. ShelfScout is ready. Tap to speak.'
      );
      return;
    }

    // WCAG 3.2.1: Cannot interrupt processing
    if (isProcessing) {
      console.log('‚ö†Ô∏è Cannot interrupt during processing');
      
      // Inform user
      AccessibilityInfo.announceForAccessibility(
        'Cannot interrupt while processing. Please wait for the response.'
      );
      return;
    }

    // Take photo while recording
    if (isRecording) {
      console.log('üì∏ Double tap while recording - capturing photo');
      
      // Announce action
      AccessibilityInfo.announceForAccessibility('Taking photo.');
      
      try {
        await capturePhoto();
        console.log('‚úÖ Photo captured during recording');
        
        // Announce success
        AccessibilityInfo.announceForAccessibility(
          'Photo captured. Continue speaking your command.'
        );
      } catch (error) {
        console.error('‚ùå Photo capture error:', error);
        
        // WCAG 3.3.1: Announce error
        const errorMessage = error instanceof Error 
          ? error.message 
          : 'Failed to capture photo';
        
        AccessibilityInfo.announceForAccessibility(
          `Photo capture failed: ${errorMessage}. Continue with voice command.`
        );
      }
    }
  };

  // ============================================================================
  // Speech result handler
  // ============================================================================
  const handleSpeechResult = (transcript: string) => {
    console.log('üìù Transcript:', transcript);
    setCurrentTranscript(transcript);
  };

  // ============================================================================
  // WCAG 3.3.1: Speech error handler with clear error identification
  // ============================================================================
  const handleSpeechError = (error: any) => {
    console.error('‚ùå Speech error:', error);
    setIsRecording(false);
    
    // WCAG 3.3.1: Identify and announce error
    const errorMessage = error?.error?.message || 'Speech recognition error';
    
    // Don't show alert for "already started" errors (system quirk)
    if (!errorMessage.includes('already started')) {
      // Announce error
      AccessibilityInfo.announceForAccessibility(
        `Speech recognition error: ${errorMessage}. Please try again.`
      );
      
      Alert.alert(
        'Speech Recognition Error', 
        errorMessage + '. Please try again.',
        [{ text: 'OK', style: 'default' }]
      );
    }
  };

  // ============================================================================
  // Process voice command
  // ============================================================================
  const processVoiceCommand = async (transcript: string) => {
    if (isProcessingRef.current) {
      console.log('‚ö†Ô∏è Already processing');
      return;
    }

    isProcessingRef.current = true;
    setIsProcessing(true);
    
    try {
      console.log('‚ö° Processing command:', transcript);
      
      // WCAG 4.1.3: Announce processing state
      AccessibilityInfo.announceForAccessibility(
        'Processing your request. Please wait.'
      );
      
      // Capture photo
      const photoUri = await capturePhoto();
      console.log('üì∏ Photo:', photoUri);
      
      if (!photoUri) {
        throw new Error('Failed to capture photo. Please ensure camera is working.');
      }
      
      // Send to backend
      const response = await sendToWorkflow({
        text: transcript,
        imageUri: photoUri,
      });

      console.log('‚úÖ Response:', response.text.substring(0, 50) + '...');

      if (!response.text) {
        throw new Error('No response received from server');
      }

      // Transition from processing to speaking
      setIsProcessing(false);
      setIsSpeaking(true);

      // WCAG 4.1.3: Announce speaking state
      AccessibilityInfo.announceForAccessibility(
        'Response received. Speaking now.'
      );

      // Speak response
      await speak(response.text);
      
      // Speaking finished naturally
      setIsSpeaking(false);
      
      // WCAG 4.1.3: Announce ready state
      AccessibilityInfo.announceForAccessibility(
        'Response complete. ShelfScout is ready. Tap to speak.'
      );
      
    } catch (error) {
      console.error('‚ùå Processing error:', error);
      
      setIsProcessing(false);
      setIsSpeaking(false);
      
      // WCAG 3.3.1: Detailed error identification
      const errorMessage = error instanceof Error 
        ? error.message 
        : 'An unknown error occurred';
      
      const userMessage = errorMessage.includes('Network') 
        ? 'Network error. Please check your internet connection and try again.'
        : errorMessage.includes('timeout')
        ? 'Request timed out. The server took too long to respond. Please try again.'
        : errorMessage.includes('photo')
        ? errorMessage // Already formatted
        : `Error: ${errorMessage}. Please try again.`;
      
      // Announce error
      AccessibilityInfo.announceForAccessibility(userMessage);
      
      Alert.alert(
        'Error',
        userMessage,
        [{ text: 'OK', style: 'default' }]
      );
    } finally {
      setCurrentTranscript('');
      isProcessingRef.current = false;
    }
  };

  // ============================================================================
  // WCAG 1.1.1: Loading state with text alternative
  // ============================================================================
  if (!device) {
    return (
      <View 
        style={styles.loadingContainer}
        accessible={true}
        accessibilityLabel="Loading camera. Please wait."
        accessibilityRole="none"
        accessibilityLiveRegion="polite"
      >
        <ActivityIndicator 
          size="large" 
          color={COLORS.PRIMARY}
          accessible={false} // Decorative for blind users
        />
        <Text 
          style={styles.loadingText}
          accessible={true}
          accessibilityRole="text"
        >
          Loading camera...
        </Text>
      </View>
    );
  }

  // ============================================================================
  // Helper: Get status info for display
  // ============================================================================
  const getStatusInfo = () => {
    if (isSpeaking) {
      return { text: 'Speaking...', color: COLORS.SPEAKING };
    }
    if (isProcessing) {
      return { text: 'Thinking...', color: COLORS.PROCESSING };
    }
    if (isRecording) {
      return { text: 'Listening...', color: COLORS.RECORDING };
    }
    return { text: 'Ready', color: COLORS.PRIMARY };
  };

  const statusInfo = getStatusInfo();

  // ============================================================================
  // Helper: Get instruction text
  // ============================================================================
  const getInstructionText = () => {
    if (isSpeaking || isProcessing) {
      return 'Double-tap to interrupt';
    }
    if (isRecording) {
      return 'Tap to stop & process';
    }
    return 'Tap to speak';
  };

  // ============================================================================
  // Main Render
  // ============================================================================
  return (
    <View style={styles.container}>
      {/* Camera - WCAG 1.1.1: Decorative for blind users */}
      <Camera
        ref={cameraRef}
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={true}
        photo={true}
        accessible={false}
        accessibilityElementsHidden={true}
      />

      {/* Visual Feedback - decorative, hidden from screen readers */}
      <VisualFeedback 
        isActive={isRecording || isProcessing || isSpeaking}
        isRecording={isRecording}
        isProcessing={isProcessing}
        isSpeaking={isSpeaking}
      />
      
      {/* Button Container - WCAG 2.4.3: Logical focus order */}
      <View style={styles.buttonContainer}>
        {/* Voice Button - WCAG 4.1.2: Fully accessible */}
        <VoiceButton
          isRecording={isRecording}
          isProcessing={isProcessing}
          isSpeaking={isSpeaking}
          onPress={handlePress}
          onDoubleTap={handleDoubleTap}
        />
        
        {/* Status Text - WCAG 4.1.3: Status message */}
        <Text 
          style={[styles.statusText, { color: statusInfo.color }]}
          accessible={true}
          accessibilityRole="text"
          accessibilityLiveRegion="polite"
          accessibilityLabel={`Status: ${statusInfo.text}`}
        >
          {statusInfo.text}
        </Text>

        {/* Transcript Display - WCAG 4.1.3: Live region */}
        {isRecording && currentTranscript && (
          <View 
            style={styles.transcriptContainer}
            accessible={true}
            accessibilityRole="text"
            accessibilityLiveRegion="polite"
            accessibilityLabel={`Your words: ${currentTranscript}`}
          >
            <Text style={styles.transcriptText}>{currentTranscript}</Text>
          </View>
        )}

        {/* Instruction Text - WCAG 3.3.2: Labels or Instructions */}
        <Text 
          style={styles.instructionText}
          accessible={true}
          accessibilityRole="text"
          accessibilityLabel={`Instructions: ${getInstructionText()}`}
        >
          {getInstructionText()}
        </Text>
      </View>

      {/* Permission Button - WCAG 3.3.2: Clear call to action */}
      {!hasPermissions && (
        <TouchableOpacity
          style={styles.permissionButton}
          onPress={initializePermissions}
          accessible={true}
          accessibilityLabel="Grant Permissions"
          accessibilityHint="Activates permission request for microphone and camera access"
          accessibilityRole="button"
        >
          <Text 
            style={styles.permissionText}
            accessible={false} // Button handles accessibility
          >
            Grant Permissions
          </Text>
        </TouchableOpacity>
      )}
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: COLORS.BACKGROUND,
  },
  loadingContainer: {
    flex: 1,
    backgroundColor: COLORS.BACKGROUND,
    justifyContent: 'center',
    alignItems: 'center',
  },
  loadingText: {
    color: COLORS.WHITE,
    marginTop: 16,
    fontSize: 16,
  },
  buttonContainer: {
    position: 'absolute',
    bottom: 100,
    left: 0,
    right: 0,
    alignItems: 'center',
  },
  statusText: {
    fontSize: 24,
    fontWeight: '600',
    marginTop: 20,
  },
  transcriptContainer: {
    position: 'absolute',
    bottom: 200,
    left: 20,
    right: 20,
    backgroundColor: 'rgba(33, 150, 243, 0.2)',
    padding: 20,
    borderRadius: 15,
    borderLeftWidth: 4,
    borderLeftColor: COLORS.RECORDING,
  },
  transcriptText: {
    color: COLORS.WHITE,
    fontSize: 18,
    lineHeight: 24,
  },
  instructionText: {
    position: 'absolute',
    bottom: -40,
    color: '#999',
    fontSize: 14,
    textAlign: 'center',
  },
  permissionButton: {
    position: 'absolute',
    top: 60,
    alignSelf: 'center',
    backgroundColor: COLORS.PRIMARY,
    paddingHorizontal: 20,
    paddingVertical: 10,
    borderRadius: 8,
    // WCAG 2.5.5: Touch target minimum 44x44
    minWidth: 44,
    minHeight: 44,
    justifyContent: 'center',
    alignItems: 'center',
  },
  permissionText: {
    color: COLORS.WHITE,
    fontSize: 16,
    fontWeight: '600',
  },
});

export default MainScreen;